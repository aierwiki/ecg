{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import scipy.io as sio\n",
    "import tqdm\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/home/jovyan/ecg/examples/cinc17/train.json\"\n",
    "DEV_DATA_PATH = \"/home/jovyan/ecg/examples/cinc17/dev.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ecg(record):\n",
    "    if os.path.splitext(record)[1] == '.npy':\n",
    "        ecg = np.load(record)\n",
    "    elif os.path.splitext(record)[1] == '.mat':\n",
    "        ecg = sio.loadmat(record)['val'].squeeze()\n",
    "    else:\n",
    "        with open(record, 'r') as fid:\n",
    "            ecg = np.fromfile(fid, dtype = np.int16)\n",
    "    \n",
    "    trunc_samp = STEP * len(ecg) // STEP    \n",
    "    return ecg[:trunc_samp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_json):\n",
    "    with open(data_json, 'r') as fid:\n",
    "        data = [json.loads(l) for l in fid]\n",
    "    labels = []; ecgs = []\n",
    "    \n",
    "    for d in tqdm.tqdm(data):\n",
    "        labels.append(d['labels'])\n",
    "        ecgs.append(load_ecg(d['ecg']))\n",
    "    \n",
    "    return ecgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(x):\n",
    "    x = np.hstack(x)\n",
    "    return np.mean(x).astype(np.float32), np.std(x).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_info(ecg, labels):\n",
    "    mean, std = compute_mean_std(ecg)\n",
    "    classes = sorted(set(l for label in labels for l in label))\n",
    "    int_to_class = dict(zip(range(len(classes)), classes))\n",
    "    class_to_int = {c : i for i, c in int_to_class.items()}\n",
    "    return mean, std, int_to_class, class_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x, val = 0, dtype = np.float32):\n",
    "    max_len = max(len(i) for i in x)\n",
    "    padded = np.full((len(x), max_len), val, dtype = dtype)\n",
    "    for e, i in enumerate(x):\n",
    "        padded[e, : len(i)] = i\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(x, y, mean, std, class_to_int):\n",
    "    # process x\n",
    "    x = pad(x)\n",
    "    x = (x - mean) / std\n",
    "    x = x[:, :, None]\n",
    "    \n",
    "    # process y\n",
    "    y = pad([[class_to_int[c] for c in s] for s in y], val = 3, dtype=np.int32)\n",
    "    y = keras.utils.np_utils.to_categorical(y, num_classes = len(class_to_int))\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7676/7676 [00:13<00:00, 566.84it/s]\n"
     ]
    }
   ],
   "source": [
    "ecgs_train, labels_train = load_dataset(TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std, int_to_class, class_to_int = get_data_info(ecgs_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = process(ecgs_train, labels_train, mean, std, class_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7676, 18286, 1), (7676, 71, 4))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 852/852 [00:01<00:00, 562.69it/s]\n"
     ]
    }
   ],
   "source": [
    "ecgs_dev, labels_dev = load_dataset(DEV_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std, int_to_class, class_to_int = get_data_info(ecgs_dev, labels_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_x, dev_y = process(ecgs_dev, labels_dev, mean, std, class_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((852, 18258, 1), (852, 71, 4))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_x.shape, dev_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Add\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropad(x):\n",
    "    y = K.zeros_like(x)\n",
    "    return K.concatenate([x, y], axis = 2)\n",
    "\n",
    "def zeropad_output_shape(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    assert len(shape) == 3\n",
    "    shape[2] *= 2\n",
    "    return tuple(shape)\n",
    "\n",
    "def resnet_block(layer, num_filters, subsample_length, block_index, conv_increase_channels_at, conv_num_skip):\n",
    "    shortcut = MaxPooling1D(pool_size = subsample_length)(layer)\n",
    "    zero_pad = (block_index % conv_increase_channels_at) == 0 and block_index > 0\n",
    "    \n",
    "    if zero_pad is True:\n",
    "        shortcut = Lambda(zeropad, output_shape = zeropad_output_shape)(shortcut)\n",
    "        \n",
    "    for i in range(conv_num_skip):\n",
    "        if not (block_index == 0 and i == 0):\n",
    "            layer = BatchNormalization()(layer)\n",
    "            layer = Activation('relu')(layer)\n",
    "            layer = Dropout(0.2)(layer)\n",
    "        \n",
    "        layer = Conv1D(filters = num_filters,\n",
    "                      kernel_size = 16,\n",
    "                      strides = subsample_length if i == 0 else 1,\n",
    "                      padding = 'same',\n",
    "                      kernel_initializer = 'he_normal')(layer)\n",
    "    layer = Add()([shortcut, layer])\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = Input(shape = [None, 1], dtype = 'float32', name = 'inputs')\n",
    "    \n",
    "    # add resnet layer\n",
    "    layer = Conv1D(filters = 32,\n",
    "                  kernel_size = 16,\n",
    "                  strides = 1 ,\n",
    "                  padding = 'same',\n",
    "                  kernel_initializer = 'he_normal')(inputs)\n",
    "    \n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    \n",
    "    conv_subsample_lengths = [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n",
    "    for index, subsample_length in enumerate(conv_subsample_lengths): \n",
    "        num_filters = 2 ** (index // 4) * 32 # start conv's filter num is 32, and increase filter num every 4 layers\n",
    "        layer = resnet_block(layer, num_filters, subsample_length, index, 4, 2) # 4 is increase channel step, 2 is conv layer num of one resnet block\n",
    "        \n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    \n",
    "    # add output layer\n",
    "    layer = TimeDistributed(Dense(4))(layer)\n",
    "    output = Activation('softmax')(layer)\n",
    "    \n",
    "    model = Model(inputs = [inputs], outputs = [output])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr = 0.001, clipnorm = 1)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping = keras.callbacks.EarlyStopping(patience = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(factor = 0.1, patience = 2, min_lr = 0.001 * 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint('save', save_best_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /srv/conda/envs/notebook/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 10 samples, validate on 10 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x[:10], train_y[:10], batch_size = 32, epochs = 10, \n",
    "          validation_data = (dev_x[:10], dev_y[:10]), callbacks = [reduce_lr, stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
